{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO22lNObpNp8JU8ccW7FBWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomas-greig/MSc/blob/main/compare_f.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIhaeOIW_XjY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "from numpy.fft import fft2, ifft2, fftshift\n",
        "from numba import njit\n",
        "\n",
        "# =========================\n",
        "# Global Parameters (unchanged)\n",
        "# =========================\n",
        "Lx, Ly = 100, 100\n",
        "N = 5000\n",
        "steps = 300_000_000           # very heavy; reduce for speed if needed\n",
        "b_over_T = 3                  # β/T\n",
        "J_over_T = b_over_T/3.0       # J/T\n",
        "eps = 0\n",
        "sample_every = N*1000\n",
        "relaxation_index = int(0.2 * steps / sample_every)\n",
        "\n",
        "runs = 15\n",
        "base_seed = 52341\n",
        "\n",
        "# --- τ-leap parameters ---\n",
        "D0 = 1.0\n",
        "dt = 0.99 / (8.0 * D0)\n",
        "\n",
        "# =========================\n",
        "# Helpers (trimmed to essentials)\n",
        "# =========================\n",
        "def compute_2D_correlation(data):\n",
        "    \"\"\"Streaming FFT accumulation (float32/complex64).\"\"\"\n",
        "    T, Lx_, Ly_ = data.shape\n",
        "    mean_n = data.mean(axis=0).astype(np.float32, copy=False)\n",
        "    corr_fft = np.zeros((Lx_, Ly_), dtype=np.complex64)\n",
        "    for k in range(T):\n",
        "        frame32 = data[k].astype(np.float32, copy=False)\n",
        "        f = np.fft.fft2(frame32 - mean_n)\n",
        "        corr_fft += f * np.conj(f)\n",
        "    corr = np.real(np.fft.ifft2(corr_fft)).astype(np.float32, copy=False) / (T * Lx_ * Ly_)\n",
        "    return fftshift(corr)\n",
        "\n",
        "def directional_cuts(corr_2d):\n",
        "    \"\"\"Return r_x, cut_x, r_y, cut_y (cuts from centre toward +x and +y).\"\"\"\n",
        "    Lx_, Ly_ = corr_2d.shape\n",
        "    cx, cy = Lx_ // 2, Ly_ // 2\n",
        "    cut_x = corr_2d[cx:, cy]\n",
        "    cut_y = corr_2d[cx, cy:]\n",
        "    r_x = np.arange(0, len(cut_x))\n",
        "    r_y = np.arange(0, len(cut_y))\n",
        "    return r_x, cut_x, r_y, cut_y\n",
        "\n",
        "def powerlaw_fit(r, c, r_window=None, use_abs=False, positive_only=False, min_pts=2):\n",
        "    \"\"\"Fit log(y) vs log(r) via linear regression.\"\"\"\n",
        "    y = np.abs(c) if use_abs else c\n",
        "    mask = np.isfinite(r) & np.isfinite(y) & (y > 0)\n",
        "    if r_window is not None:\n",
        "        rmin, rmax = r_window\n",
        "        mask &= (r > rmin) & (r < rmax)\n",
        "    if np.count_nonzero(mask) < min_pts:\n",
        "        return np.nan, np.nan, np.nan, mask\n",
        "    lr = np.log(r[mask]); ly = np.log(y[mask])\n",
        "    slope, intercept, r_value, _, _ = linregress(lr, ly)\n",
        "    return slope, intercept, r_value**2, mask\n",
        "\n",
        "def stats_arr(arr):\n",
        "    a = arr[np.isfinite(arr)]\n",
        "    if a.size == 0: return np.nan, np.nan\n",
        "    return np.mean(a), (np.std(a, ddof=1) if a.size > 1 else 0.0)\n",
        "\n",
        "# =========================\n",
        "# τ-LEAP SIMULATION (Numba) — pass DRIFT_ALIGN explicitly\n",
        "# =========================\n",
        "@njit\n",
        "def nn_sum_numba(occ, x, y, Lx, Ly):\n",
        "    return (occ[(x-1)%Lx,y] + occ[(x+1)%Lx,y] +\n",
        "            occ[x,(y-1)%Ly] + occ[x,(y+1)%Ly])\n",
        "\n",
        "@njit\n",
        "def one_sweep_tau(positions, occupancy, Lx, Ly, b_over_T, J_over_T, DRIFT_ALIGN):\n",
        "    \"\"\"\n",
        "    τ-leap (discrete-time CTMC):\n",
        "      ΔE_tot = ΔE_on + ΔE_nn - drive,  where drive encodes drift via DRIFT_ALIGN.\n",
        "      λ_dir = 2*D0 * sigmoid(ΔE_tot),\n",
        "      p_dir = λ_dir * dt,  p_stay = 1 - Σ p_dir.\n",
        "    \"\"\"\n",
        "    N = positions.shape[0]\n",
        "\n",
        "    # Random permutation (without replacement) per sweep\n",
        "    order = np.arange(N)\n",
        "    for i in range(N-1, 0, -1):\n",
        "        j = np.random.randint(0, i+1)\n",
        "        order[i], order[j] = order[j], order[i]\n",
        "\n",
        "    for t in range(N):\n",
        "        idx = order[t]\n",
        "        x0 = positions[idx,0]; y0 = positions[idx,1]\n",
        "\n",
        "        n0 = occupancy[x0,y0]\n",
        "        S0 = (occupancy[(x0-1)%Lx,y0] + occupancy[(x0+1)%Lx,y0] +\n",
        "              occupancy[x0,(y0-1)%Ly] + occupancy[x0,(y0+1)%Ly])\n",
        "\n",
        "        # RIGHT\n",
        "        xr, yr = (x0+1)%Lx, y0\n",
        "        nr = occupancy[xr,yr]\n",
        "        Sr = (occupancy[(xr-1)%Lx,yr] + occupancy[(xr+1)%Lx,yr] +\n",
        "              occupancy[xr,(yr-1)%Ly] + occupancy[xr,(yr+1)%Ly])\n",
        "        dE_on = 2.0*b_over_T*(1.0 + (nr - n0))\n",
        "        dE_nn = - J_over_T * ((Sr - S0) - 1.0)\n",
        "        drive = float(DRIFT_ALIGN[1])   # Δx = +1 for RIGHT\n",
        "        dE = dE_on + dE_nn - drive\n",
        "        br = 1.0/(1.0 + np.exp(dE))\n",
        "        lam_r = 2.0*D0 * br\n",
        "\n",
        "        # LEFT\n",
        "        xl, yl = (x0-1)%Lx, y0\n",
        "        nl = occupancy[xl,yl]\n",
        "        Sl = (occupancy[(xl-1)%Lx,yl] + occupancy[(xl+1)%Lx,yl] +\n",
        "              occupancy[xl,(yl-1)%Ly] + occupancy[xl,(yl+1)%Ly])\n",
        "        dE_on = 2.0*b_over_T*(1.0 + (nl - n0))\n",
        "        dE_nn = - J_over_T * ((Sl - S0) - 1.0)\n",
        "        drive = float(DRIFT_ALIGN[0])   # Δx = -1 for LEFT\n",
        "        dE = dE_on + dE_nn - drive\n",
        "        bl = 1.0/(1.0 + np.exp(dE))\n",
        "        lam_l = 2.0*D0 * bl\n",
        "\n",
        "        # UP\n",
        "        xu, yu = x0, (y0+1)%Ly\n",
        "        nu = occupancy[xu,yu]\n",
        "        Su = (occupancy[(xu-1)%Lx,yu] + occupancy[(xu+1)%Lx,yu] +\n",
        "              occupancy[xu,(yu-1)%Ly] + occupancy[xu,(yu+1)%Ly])\n",
        "        dE_on = 2.0*b_over_T*(1.0 + (nu - n0))\n",
        "        dE_nn = - J_over_T * ((Su - S0) - 1.0)\n",
        "        drive = float(DRIFT_ALIGN[2])   # Δx = 0 for UP\n",
        "        dE = dE_on + dE_nn - drive\n",
        "        bu = 1.0/(1.0 + np.exp(dE))\n",
        "        lam_u = 2.0*D0 * bu\n",
        "\n",
        "        # DOWN\n",
        "        xd, yd = x0, (y0-1)%Ly\n",
        "        nd = occupancy[xd,yd]\n",
        "        Sd = (occupancy[(xd-1)%Lx,yd] + occupancy[(xd+1)%Lx,yd] +\n",
        "              occupancy[xd,(yd-1)%Ly] + occupancy[xd,(yd+1)%Ly])\n",
        "        dE_on = 2.0*b_over_T*(1.0 + (nd - n0))\n",
        "        dE_nn = - J_over_T * ((Sd - S0) - 1.0)\n",
        "        drive = float(DRIFT_ALIGN[3])   # Δx = 0 for DOWN\n",
        "        dE = dE_on + dE_nn - drive\n",
        "        bd = 1.0/(1.0 + np.exp(dE))\n",
        "        lam_d = 2.0*D0 * bd\n",
        "\n",
        "        # probabilities p = λ Δt; remainder is stay\n",
        "        pr = lam_r * dt\n",
        "        pl = lam_l * dt\n",
        "        pu = lam_u * dt\n",
        "        pd = lam_d * dt\n",
        "        psum = pr + pl + pu + pd\n",
        "\n",
        "        if psum > 1.0:\n",
        "            s = 0.999999 / psum\n",
        "            pr *= s; pl *= s; pu *= s; pd *= s\n",
        "            psum = pr + pl + pu + pd\n",
        "\n",
        "        u = np.random.random()\n",
        "        if u < pr:\n",
        "            x1, y1 = (x0+1)%Lx, y0\n",
        "        elif u < pr + pl:\n",
        "            x1, y1 = (x0-1)%Lx, y0\n",
        "        elif u < pr + pl + pu:\n",
        "            x1, y1 = x0, (y0+1)%Ly\n",
        "        elif u < psum:\n",
        "            x1, y1 = x0, (y0-1)%Ly\n",
        "        else:\n",
        "            x1, y1 = x0, y0  # stay\n",
        "\n",
        "        if (x1 != x0) or (y1 != y0):\n",
        "            positions[idx,0] = x1; positions[idx,1] = y1\n",
        "            occupancy[x0,y0] -= 1; occupancy[x1,y1] += 1\n",
        "\n",
        "@njit\n",
        "def simulate_numba(Lx, Ly, N, steps, sample_every, b_over_T, J_over_T, seed, DRIFT_ALIGN):\n",
        "    if seed >= 0:\n",
        "        np.random.seed(seed)\n",
        "    positions = np.empty((N,2), dtype=np.int32)\n",
        "    positions[:,0] = np.random.randint(0, Lx, size=N)\n",
        "    positions[:,1] = np.random.randint(0, Ly, size=N)\n",
        "    occupancy = np.zeros((Lx, Ly), dtype=np.int16)\n",
        "    for i in range(N):\n",
        "        occupancy[positions[i,0], positions[i,1]] += 1\n",
        "    n_samples = steps // sample_every + 1\n",
        "    series = np.zeros((n_samples, Lx, Ly), dtype=np.int16)\n",
        "    sidx = 0; series[sidx,:,:] = occupancy; sidx += 1\n",
        "    step = 0\n",
        "    while step < steps:\n",
        "        one_sweep_tau(positions, occupancy, Lx, Ly, b_over_T, J_over_T, DRIFT_ALIGN)\n",
        "        step += N\n",
        "        while (sidx < n_samples) and (step >= sidx*sample_every):\n",
        "            series[sidx,:,:] = occupancy\n",
        "            sidx += 1\n",
        "            if sidx >= n_samples:\n",
        "                break\n",
        "    return series\n",
        "\n",
        "# =========================\n",
        "# Per-run stats (no plotting)\n",
        "# =========================\n",
        "def compute_run_stats(series, window=(1,20)):\n",
        "    stationary = series[relaxation_index:]\n",
        "    corr_2d = compute_2D_correlation(stationary)\n",
        "    r_x, cut_x, r_y, cut_y = directional_cuts(corr_2d)\n",
        "    sx_all, _, r2x_all, _ = powerlaw_fit(r_x[1:], cut_x[1:], r_window=None, use_abs=False, positive_only=True)\n",
        "    sy_all_mag, _, r2y_all, _ = powerlaw_fit(r_y[1:], cut_y[1:], r_window=None, use_abs=True,  positive_only=False)\n",
        "    sx_rng, ix_rng, r2x_rng, maskx = powerlaw_fit(r_x[1:], cut_x[1:], r_window=window, use_abs=False, positive_only=True)\n",
        "    sy_rng_mag, iy_rng, r2y_rng, masky = powerlaw_fit(r_y[1:], cut_y[1:], r_window=window, use_abs=True,  positive_only=False)\n",
        "    return corr_2d, (sx_all, sy_all_mag, sx_rng, sy_rng_mag, r2x_all, r2y_all, r2x_rng, r2y_rng), ((r_x[1:], cut_x[1:], maskx, ix_rng, sx_rng),\n",
        "                                                                                                   (r_y[1:], np.abs(cut_y[1:]), masky, iy_rng, sy_rng_mag))\n",
        "\n",
        "# =========================\n",
        "# Run for f in {1,2,3}, aggregate, and plot shared axes\n",
        "# =========================\n",
        "f_values = [1, 2, 3]\n",
        "window = (1, 20)\n",
        "\n",
        "summary = {}          # store mean±sd slopes per f\n",
        "fit_lines_x = {}      # per f: (rr, yy) for x-cut\n",
        "fit_lines_y = {}      # per f: (rr, yy) for y-cut\n",
        "\n",
        "colors = {1: 'C0', 2: 'C1', 3: 'C2'}\n",
        "\n",
        "for f in f_values:\n",
        "    # Drift along +x with magnitude f: DRIFT_ALIGN = [-f, +f, 0, 0] for [LEFT, RIGHT, UP, DOWN]\n",
        "    DRIFT_ALIGN = np.array([-f, +f, 0, 0], dtype=np.int8)\n",
        "\n",
        "    # Accumulators\n",
        "    sum_corr_2d = None\n",
        "    sx_rng_list, sy_rng_list = [], []\n",
        "\n",
        "    for i in range(runs):\n",
        "        seed = base_seed + 1000*f + i\n",
        "        series = simulate_numba(Lx, Ly, N, steps, sample_every, b_over_T, J_over_T, seed, DRIFT_ALIGN)\n",
        "\n",
        "        corr_2d, stats, cutpacks = compute_run_stats(series, window=window)\n",
        "        sx_all, sy_all, sx_rng, sy_rng, *_ = stats\n",
        "        sx_rng_list.append(sx_rng)\n",
        "        sy_rng_list.append(sy_rng)\n",
        "\n",
        "        if sum_corr_2d is None:\n",
        "            sum_corr_2d = np.zeros_like(corr_2d, dtype=np.float64)\n",
        "        sum_corr_2d += corr_2d\n",
        "\n",
        "    # Averages across runs\n",
        "    avg_corr_2d = sum_corr_2d / runs\n",
        "    mean_sx, sd_sx = stats_arr(np.array(sx_rng_list, dtype=float))\n",
        "    mean_sy, sd_sy = stats_arr(np.array(sy_rng_list, dtype=float))\n",
        "    summary[f] = dict(mean_sx=mean_sx, sd_sx=sd_sx, mean_sy=mean_sy, sd_sy=sd_sy)\n",
        "\n",
        "    # Build fit lines using the averaged correlation and the same window\n",
        "    r_x, cut_x, r_y, cut_y = directional_cuts(avg_corr_2d)\n",
        "    rx, cx = r_x[1:], cut_x[1:]\n",
        "    ry, cy_abs = r_y[1:], np.abs(cut_y[1:])\n",
        "\n",
        "    sx_fit, ix_fit, _, maskx = powerlaw_fit(rx, cx, r_window=window, use_abs=False, positive_only=True)\n",
        "    sy_fit, iy_fit, _, masky = powerlaw_fit(ry, cy_abs, r_window=window, use_abs=False, positive_only=False)\n",
        "\n",
        "    # Smooth lines across the masked r-range\n",
        "    if np.any(maskx):\n",
        "        rr_x = np.linspace(rx[maskx].min(), rx[maskx].max(), 200)\n",
        "        yy_x = np.exp(ix_fit) * rr_x**sx_fit\n",
        "        fit_lines_x[f] = (rr_x, yy_x)\n",
        "    else:\n",
        "        fit_lines_x[f] = (np.array([1,2]), np.array([np.nan, np.nan]))\n",
        "\n",
        "    if np.any(masky):\n",
        "        rr_y = np.linspace(ry[masky].min(), ry[masky].max(), 200)\n",
        "        yy_y = np.exp(iy_fit) * rr_y**sy_fit\n",
        "        fit_lines_y[f] = (rr_y, yy_y)\n",
        "    else:\n",
        "        fit_lines_y[f] = (np.array([1,2]), np.array([np.nan, np.nan]))\n",
        "\n",
        "# =========================\n",
        "# Plot: X-cut fits (C>0) overlaid for all f\n",
        "# =========================\n",
        "plt.figure()\n",
        "for f in f_values:\n",
        "    rr, yy = fit_lines_x[f]\n",
        "    m, s = summary[f]['mean_sx'], summary[f]['sd_sx']\n",
        "    plt.loglog(rr, yy, '-', label=f\"f={f}  slope={m:.3f} ± {s:.3f}\", color=colors[f])\n",
        "plt.xlabel('r (lattice units)')\n",
        "plt.ylabel('C_x(r)')\n",
        "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# Plot: Y-cut fits (|C|) overlaid for all f\n",
        "# =========================\n",
        "plt.figure()\n",
        "for f in f_values:\n",
        "    rr, yy = fit_lines_y[f]\n",
        "    m, s = summary[f]['mean_sy'], summary[f]['sd_sy']\n",
        "    plt.loglog(rr, yy, '-', label=f\"f={f}  slope={m:.3f} ± {s:.3f}\", color=colors[f])\n",
        "plt.xlabel('r (lattice units)')\n",
        "plt.ylabel('|C_y(r)|')\n",
        "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# Console summary\n",
        "# =========================\n",
        "for f in f_values:\n",
        "    print(f\"f={f}:  x-cut slope (1<r<20) = {summary[f]['mean_sx']:.4f} ± {summary[f]['sd_sx']:.4f}   \"\n",
        "          f\"|  y-cut slope (|C|, 1<r<20) = {summary[f]['mean_sy']:.4f} ± {summary[f]['sd_sy']:.4f}\")\n"
      ]
    }
  ]
}